{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c0f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0aa1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = 'MS'\n",
    "daily = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline:\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import RandomWalkWithDrift, Naive\n",
    "\n",
    "models_basic = [\n",
    "    RandomWalkWithDrift(alias='RandomWalkWithDrift'),\n",
    "    Naive()\n",
    "]\n",
    "\n",
    "\n",
    "sf_baseline = StatsForecast(models=models_basic, freq=daily, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80229f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical Models:\n",
    "from statsforecast.models import (Holt, AutoARIMA)\n",
    "\n",
    "models_statistics = [\n",
    "    Holt(season_length=12, error_type=\"A\"),\n",
    "    AutoARIMA()\n",
    "]\n",
    "\n",
    "sf_statistics = StatsForecast(models=models_statistics, freq=daily, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Machine Learning Models:\n",
    "from mlforecast import MLForecast\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "models_ml = [\n",
    "    LinearRegression(),\n",
    "    HuberRegressor(epsilon=1.35, alpha=1e-3),\n",
    "    #svm.SVR(kernel='rbf', C=50, gamma=0.01, epsilon=0.1),\n",
    "    #KNeighborsRegressor(n_neighbors=5, weights='distance', p=2),\n",
    "    #DecisionTreeRegressor(criterion='squared_error', max_depth=12, min_samples_leaf=5, min_samples_split=5, max_features='sqrt'),\n",
    "    #HistGradientBoostingRegressor(loss='absolute_error', learning_rate=0.05, max_leaf_nodes=31, max_depth=10, min_samples_leaf=50, l2_regularization=0.1),\n",
    "    RandomForestRegressor(n_estimators=400, max_depth=20, min_samples_leaf=5, max_features='sqrt', random_state=42),\n",
    "    LGBMRegressor(num_leaves=63, learning_rate=0.05, n_estimators=500, min_child_samples=50, subsample=0.9, colsample_bytree=0.9, random_state=42),\n",
    "    #XGBRFRegressor(n_estimators=500, max_depth=6, subsample=1.0, colsample_bytree=1.0, random_state=42),\n",
    "    #MLPRegressor(hidden_layer_sizes=(128,128), activation='relu', learning_rate_init=3e-4, alpha=1e-3, max_iter=400, random_state=42)\n",
    "]\n",
    "\n",
    "ml_forecast = MLForecast(models=models_ml, freq=daily)  ##LAGS? ##DATE FEATURES? ##WINDOWS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a9b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 17:59:27,319\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-12-22 17:59:31,828\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Seed set to 1\n",
      "c:\\Users\\loren\\anaconda3\\envs\\AIS3_TIS\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "Seed set to 1\n",
      "Seed set to 1\n",
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "## Deep Learning Models:\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, RNN, LSTM, DeepAR, NLinear, KAN\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "\n",
    "h_val = 365\n",
    "input_val = 365*4\n",
    "\n",
    "models_dl = [\n",
    "    DeepAR(h=h_val, input_size=input_val, lstm_n_layers=1, trajectory_samples=100, loss=MAE(), valid_loss=MAE(), learning_rate=0.005, max_steps=200, scaler_type='standard', enable_progress_bar=True), \n",
    "    NLinear(h=h_val, input_size=input_val, loss=MAE(), scaler_type='robust', learning_rate=1e-3, max_steps=500), \n",
    "    NBEATS(h=h_val, input_size=input_val, basis='changepoint', n_basis=2, loss=MAE(), stack_types=['identity', 'trend','seasonality'], max_steps=100),\n",
    "    KAN(h=h_val, input_size=input_val, loss=MAE(), scaler_type='robust',learning_rate=1e-3,max_steps=500)\n",
    "]\n",
    "\n",
    "dl_forecast = NeuralForecast(models=models_dl, freq=daily) ##LAGS? ##Date Features??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030fc95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS3_TIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
